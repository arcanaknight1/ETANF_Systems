null = glm(API~1, data = na.omit(train.data), family = "gamma")
full = glm(API~., data = na.omit(train.data), family = "gamma")
fwd.model <- step(null, scope = list(lower = null, upper = full), direction = "forward", trace = FALSE)
fwd.roc <- roc(test.data$API, predict(fwd.model, test.data, type = "response"))
step.forward.auc[j] <- fwd.roc$auc
#backward stepwise model
bwd.model <- step(full, direction = "backward", trace = FALSE)
bwd.roc <- roc(test.data$API, predict(bwd.model, test.data, type = "response"))
step.backward.auc [j] <- bwd.roc$auc
#random forest model
rf <- randomForest(as.factor(API)~., data = train.data, mtry = 17, importance = TRUE, na.action = na.omit)
rf.pred <- predict(rf, test.data, type = "prob")
rf.roc <- roc(test.data$API, rf.pred[,2])
Rf.auc[j] <- rf.roc$auc
}
result <- rbind(result, data.frame(method = "lasso", auc = mean(lasso.auc)))
result <- rbind(result, data.frame(method = "forward", auc = mean(step.forward.auc)))
result <- rbind(result, data.frame(method = "backward", auc = mean(step.backward.auc)))
result <- rbind(result, data.frame(method = "random forest", auc = mean(Rf.auc)))
return(result)
}
testCV(ETANFdata)
# AUC by crossvalidation for each variable selection method
testCV <- function(DATA){
# combine two columns
func.data <- data.frame(DATA)
# Count the number of row of entire dataframe
n.data <- nrow(func.data)
# divide the number of rows in the dataframe into ten groups
folds <- split(sample(n.data, n.data ,replace=FALSE), as.factor(1:10))
# auc list
lasso.auc <- rep(0,10)
step.forward.auc <- rep(0,10)
step.backward.auc <- rep(0,10)
Rf.auc <- rep(0,10)
result<- data.frame("method" = character(), "auc" = numeric(), stringsAsFactors = FALSE)
for (j in 1:10){
test.data <- func.data[folds[[j]], ]
n.test <-nrow(test.data)
train.data <- func.data[-folds[[j]], ]
# lasso model
train.x <- as.matrix(train.data[, -which(names(train.data) == "ETANF")])
train.y <- train.data$ETANF
test.x <- as.matrix(test.data[, -which(names(test.data) == "ETANF")])
test.y <- test.data$ETANF
train.lasso <- glmnet(train.x, as.factor(train.y),
family = "gamma", lambda = all.se)
lasso.pred <- predict(train.lasso,
newx = data.matrix(test.data[, -which(names(test.data) == "ETANF")]))
lasso.roc <- roc(test.y, lasso.pred)
lasso.auc[j] <- lasso.roc$auc
#forward stepwise model
null = glm(ETANF~1, data = na.omit(train.data), family = "gamma")
full = glm(ETANF~., data = na.omit(train.data), family = "gamma")
fwd.model <- step(null, scope = list(lower = null, upper = full), direction = "forward", trace = FALSE)
fwd.roc <- roc(test.data$ETANF, predict(fwd.model, test.data, type = "response"))
step.forward.auc[j] <- fwd.roc$auc
#backward stepwise model
bwd.model <- step(full, direction = "backward", trace = FALSE)
bwd.roc <- roc(test.data$ETANF, predict(bwd.model, test.data, type = "response"))
step.backward.auc [j] <- bwd.roc$auc
#random forest model
rf <- randomForest(as.factor(ETANF)~., data = train.data, mtry = 17, importance = TRUE, na.action = na.omit)
rf.pred <- predict(rf, test.data, type = "prob")
rf.roc <- roc(test.data$ETANF, rf.pred[,2])
Rf.auc[j] <- rf.roc$auc
}
result <- rbind(result, data.frame(method = "lasso", auc = mean(lasso.auc)))
result <- rbind(result, data.frame(method = "forward", auc = mean(step.forward.auc)))
result <- rbind(result, data.frame(method = "backward", auc = mean(step.backward.auc)))
result <- rbind(result, data.frame(method = "random forest", auc = mean(Rf.auc)))
return(result)
}
testCV(ETANFdata)
# AUC by crossvalidation for each variable selection method
testCV <- function(DATA){
# combine two columns
func.data <- data.frame(DATA)
# Count the number of row of entire dataframe
n.data <- nrow(func.data)
# divide the number of rows in the dataframe into ten groups
folds <- split(sample(n.data, n.data ,replace=FALSE), as.factor(1:10))
# auc list
lasso.auc <- rep(0,10)
step.forward.auc <- rep(0,10)
step.backward.auc <- rep(0,10)
Rf.auc <- rep(0,10)
result<- data.frame("method" = character(), "auc" = numeric(), stringsAsFactors = FALSE)
for (j in 1:10){
test.data <- func.data[folds[[j]], ]
n.test <-nrow(test.data)
train.data <- func.data[-folds[[j]], ]
# lasso model
train.x <- as.matrix(train.data[, -which(names(train.data) == "ETANF")])
train.y <- train.data$ETANF
test.x <- as.matrix(test.data[, -which(names(test.data) == "ETANF")])
test.y <- test.data$ETANF
train.lasso <- glmnet(train.x, as.factor(train.y),
family = "poisson", lambda = all.se)
lasso.pred <- predict(train.lasso,
newx = data.matrix(test.data[, -which(names(test.data) == "ETANF")]))
lasso.roc <- roc(test.y, lasso.pred)
lasso.auc[j] <- lasso.roc$auc
#forward stepwise model
null = glm(ETANF~1, data = na.omit(train.data), family = "poisson")
full = glm(ETANF~., data = na.omit(train.data), family = "poisson")
fwd.model <- step(null, scope = list(lower = null, upper = full), direction = "forward", trace = FALSE)
fwd.roc <- roc(test.data$ETANF, predict(fwd.model, test.data, type = "response"))
step.forward.auc[j] <- fwd.roc$auc
#backward stepwise model
bwd.model <- step(full, direction = "backward", trace = FALSE)
bwd.roc <- roc(test.data$ETANF, predict(bwd.model, test.data, type = "response"))
step.backward.auc [j] <- bwd.roc$auc
#random forest model
rf <- randomForest(as.factor(ETANF)~., data = train.data, mtry = 17, importance = TRUE, na.action = na.omit)
rf.pred <- predict(rf, test.data, type = "prob")
rf.roc <- roc(test.data$ETANF, rf.pred[,2])
Rf.auc[j] <- rf.roc$auc
}
result <- rbind(result, data.frame(method = "lasso", auc = mean(lasso.auc)))
result <- rbind(result, data.frame(method = "forward", auc = mean(step.forward.auc)))
result <- rbind(result, data.frame(method = "backward", auc = mean(step.backward.auc)))
result <- rbind(result, data.frame(method = "random forest", auc = mean(Rf.auc)))
return(result)
}
testCV(ETANFdata)
#loading libraries used
library(flexdashboard)
library(shiny)
library(reshape2)
library(dplyr)
library(plotly)
library(htmltools)
library(httr)
#Building the WPRDC Get request
ckanSQL <- function(url) {
# Make the Request
r <- RETRY("GET", URLencode(url))
# Extract Content
c <- content(r, "text")
# Basic gsub to make NA's consistent with R
json <- gsub('NaN', 'NA', c, perl = TRUE)
# Create Dataframe
data.frame(jsonlite::fromJSON(json)$result$records)
}
races <- sort(c("Black", "White", "Hispanic", "Asian", "American Indian"))
#main data call with date filter and formatting
JailInput <- reactive({
#building API query with date filter
url <-paste0("http://data.wprdc.org/api/3/action/datastore_search_sql?sql=SELECT%20%22Date%22%2C%20%22Gender%22%2C%20%22Race%22%2C%20%22Age%20at%20Booking%22%20AS%20%22AgeatBooking%22%20FROM%20%2266cdcd57-6c92-4aaa-8800-0ed9d8f03e22%22%20WHERE%20%22Date%22%20%3E=%20%27", input$DateSelect[1], "%27%20AND%20%22Date%22%20%3C=%20%27", input$DateSelect[2], "%27")
#load and clean data
jail.load <- ckanSQL(url) %>%
mutate(Gender = recode(Gender, "M" = "Male", "F" = "Female"),
Race = factor(recode(Race, "B" = "Black",
"W" = "White",
"H" = "Hispanic",
"A" = "Asian",
"I" = "American Indian",
"U" = "Unknown",
"x" = NULL), levels = c("Black", "White", "Hispanic", "Asian", "American Indian", "Unknown")),
Date = as.Date(Date),
AgeatBooking = as.numeric(AgeatBooking))
})
#Main reactive function for app
jaInput <- reactive({
# Booking Age Filter
jail <- JailInput() %>%
filter(AgeatBooking >= input$BookingAgeSelect[1] & AgeatBooking <= input$BookingAgeSelect[2])
# Race Filter
if (length(input$RaceSelect) > 0 ) {
jail <- subset(jail, Race %in% input$RaceSelect)
}
if (length(input$GenderSelect) > 0 ) {
jail <- subset(jail, Gender %in% input$GenderSelect)
}
return(jail)
})
#Reactive function for gender guage
jaGInput <- reactive({
jail <- JailInput() %>%
filter(AgeatBooking >= input$BookingAgeSelect[1] & AgeatBooking <= input$BookingAgeSelect[2])
# Race Filter
if (length(input$RaceSelect) > 0 ) {
jail <- subset(jail, Race %in% input$RaceSelect)
}
return(jail)
})
#Reactive function for race valuebox
jaRInput <- reactive({
# Booking Age Filter
jail <- JailInput() %>%
filter(AgeatBooking >= input$BookingAgeSelect[1] & AgeatBooking <= input$BookingAgeSelect[2])
# Race Filter
if (length(input$RaceSelect) > 0 ) {
jail <- subset(jail, Race %in% input$RaceSelect)
}
if (length(input$GenderSelect) > 0 ) {
jail <- subset(jail, Gender %in% input$GenderSelect)
}
return(jail)
})
#Reset filters
observeEvent(input$reset, {
updateSelectInput(session, "RaceSelect", selected = c("Black", "White"))
updateSliderInput(session, "BookingAgeSelect", value = c(18, 40))
updateDateRangeInput(session, "DateSelect", start = Sys.Date()-30, end = Sys.Date())
updateCheckboxGroupInput(session, "GenderSelect", choices = c("Male", "Female"), selected = c("Male", "Female"))
showNotification("You have successfully reset the filters", type = "message")
})
# Read in the school data
elementary <- read.table("http://www.andrew.cmu.edu/user/achoulde/95791/projects/Project%20C/elementary.csv",header = TRUE, sep = ",")
middle <- read.table("http://www.andrew.cmu.edu/user/achoulde/95791/projects/Project%20C/middle.csv",header = TRUE, sep = ",")
high <- read.table("http://www.andrew.cmu.edu/user/achoulde/95791/projects/Project%20C/high.csv",header = TRUE, sep = ",")
#Set seed
set.seed(1234)
# Call libraries
# ADD libraries here
library(ggplot2)
library(glmnet)
library(pROC)
library(plyr)
library(randomForest)
library(margins)
# Re-coding variables
#Charter", "Direct", "Not Direct"
elementary <- mutate(elementary, CHARTER = as.factor(mapvalues(CHARTER, c("?", "D", "Y"), c(0, 1,2))),
VALID = as.integer(VALID),
ACS_CORE = as.integer(ACS_CORE),
AVG_ED = as.double(AVG_ED))
middle <- mutate(middle, CHARTER = as.factor(mapvalues(CHARTER, c("?", "D", "Y"), c(0, 1,2))),
VALID = as.integer(VALID),
ACS_CORE = as.integer(ACS_CORE),
AVG_ED = as.double(AVG_ED))
high <- mutate(high, CHARTER = as.factor(mapvalues(CHARTER, c("?", "D", "Y"), c(0, 1,2))),
VALID = as.integer(VALID),
ACS_CORE = as.integer(ACS_CORE),
AVG_ED = as.double(AVG_ED))
# Clean up the datasets
elementary[elementary == "?"] <- NA
middle[middle == "?"] <- NA
high[high == "?"] <- NA
#AVG_ED, VALID numeric
# Recode Dataset
for (i in 3:8){
elementary[i] <- ifelse(elementary[i] == "Yes", 1,0)
middle[i] <- ifelse(middle[i] == "Yes", 1,0)
high[i] <- ifelse(high[i] == "Yes", 1,0)
}
elementary[18] <- ifelse(elementary[18] == "High", 1,0)
middle[18] <- ifelse(middle[18] == "High", 1,0)
high[18] <- ifelse(high[18] == "High", 1,0)
# Merge dataset
all.schools <- dplyr::bind_rows(elementary,middle,high)
# Data cleaning, especially NAs, for lasso; Delete two variables mostly with NAs
elementary <- as.data.frame(elementary[, -which(names(elementary) == "ACS_CORE")])
elementary <- na.omit(elementary)
middle <- na.omit(middle)
high <- na.omit(high)
all.schools <- na.omit(all.schools)
#A function to put multiple plots on a same drawing from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
View(all.schools)
### Variable selection
# The number of rows in dataset
n.ETANF <- nrow(ETANFdata)
###
# Extract covariates matrix (for lasso)
ETANF.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# Extract response variable (for lasso)
ETANF.y <- ETANFdata$ETANF
# fit lasso
ETANF.lasso <-glmnet(ETANF.x, as.factor(ETANF.y), family = "poisson")
### Variable selection
# The number of rows in dataset
n.ETANF <- nrow(ETANFdata)
###
# Extract covariates matrix (for lasso)
ETANF.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# Extract response variable (for lasso)
ETANF.y <- ETANFdata$ETANF
# fit lasso
ETANF.lasso <-glmnet(ETANF.x, ETANF.y, family = "poisson")
# Loading libraries needed for analysis
library(ggplot2)
library(glmnet)
library(pROC)
library(plyr)
library(dplyr)
library(randomForest)
library(margins)
library(party)
install.packages(party, dependencies = T)
install.packages("party", dependencies = T)
### Variable selection
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
# Loading libraries needed for analysis
library(ggplot2)
library(glmnet)
library(pROC)
library(plyr)
library(dplyr)
library(randomForest)
library(margins)
library(partykit)
#loading data and redefining "-" symbols as NA
ETANFload <- read.table("Data_Analysis_Spreadsheet.csv", header = TRUE, sep = ",", na.strings = "-")
#Removing unused Employment training variable
ETANFdata <- ETANFload[, c(1:16, 18, 19)]
#Set seed
set.seed(1234)
### Variable selection
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
install.packages("partykit", dependencies = T)
install.packages("partykit", dependencies = T)
# Loading libraries needed for analysis
library(ggplot2)
library(glmnet)
library(pROC)
library(plyr)
library(dplyr)
library(randomForest)
library(margins)
library(partykit)
# Loading libraries needed for analysis
library(ggplot2)
library(glmnet)
library(pROC)
library(plyr)
library(dplyr)
library(randomForest)
library(margins)
library(party)
#loading data and redefining "-" symbols as NA
ETANFload <- read.table("Data_Analysis_Spreadsheet.csv", header = TRUE, sep = ",", na.strings = "-")
#Removing unused Employment training variable
ETANFdata <- ETANFload[, c(1:16, 18, 19)]
#Set seed
set.seed(1234)
### Variable selection
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
rf.test1 <- varimp(rf1, conditional=TRUE)
### Variable selection
#imputing missing values
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
etanf.imp <- missForest()
### Variable selection
#imputing missing values
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
rf.test1 <- varimp(rf1, conditional=TRUE, na.action = na.omit)
### Variable selection
#imputing missing values
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, na.action = na.omit, control=cforest_unbiased(mtry=2,ntree=50))
### Variable selection
#imputing missing values
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
rf.test1 <- varimp(rf1, conditional=TRUE)
### Variable selection
#imputing missing values
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == "ETANF")])
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
rf.test1 <- varimp(rf1)
rf.test2 <- varimpAUC(rf1)
rf.test1
### Variable selection
#extracting variables
etanf.x <- as.matrix(ETANFdata[, -which(names(ETANFdata) == c("ETANF", "County_ID", "County", "PA_Region", "Year"))])
# fit the random forest
rf1 <- cforest(ETANF ~ etanf.x , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
etanf.x
as.matrix(ETANFdata[, -which(names(ETANFdata) == c("ETANF", "County_ID", "County", "PA_Region", "Year"))])
### Variable selection
#extracting variables
etanf.x <- ETANFdata[, -which(names(ETANFdata) == c("ETANF", "County_ID", "County", "PA_Region", "Year"))]
# fit the random forest
rf1 <- cforest(ETANF ~ . , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
### Variable selection
#extracting variables
etanf.x <- ETANFdata[, -which(names(ETANFdata) == c("ETANF", "County_ID", "County", "PA_Region", "Year"))]
# fit the random forest
rf1 <- cforest(ETANF ~ etanf.x , data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
etanf.x
### Variable selection
# fit the random forest
rf1 <- cforest(ETANF ~ . - County_ID - County - PA_Region - Year, data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test1
### Variable selection
# fit the random forest
rf1 <- cforest(ETANF ~ . - County_ID, data= ETANFdata, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test1
View(ETANFdata)
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test1
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test2 <- varimp(rf1, conditional = T)
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
rf2 <- cforest(ETANF ~ ., data= etanf.x, na.action = na.omit, control=cforest_unbiased(mtry=2,ntree=50))
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
rf2 <- cforest(ETANF ~ ., data= na.omit(etanf.x), control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test2 <- varimp(rf2, conditional = T)
rf.test1
#variable importance is, in order: SNAP, SSI, CHIP, Medicaid, Population, Pov_Rate, Ed_Attain_HSandAbove,
rf.test2
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
rf2 <- cforest(ETANF ~ ., data= na.omit(etanf.x), control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
rf.test1 <- varimp(rf1)
rf.test2 <- varimp(rf2, conditional = T)
rf.test1
#variable importance is, in order: SNAP, SSI, CHIP, Medicaid, Population, Ed_Attain_HSandAbove, Pov_Rate, WIC, ED_Attain_BAandAbove
rf.test2
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
rf2 <- cforest(ETANF ~ ., data= na.omit(etanf.x), control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
set.seed(1234)
rf.test1 <- varimp(rf1)
rf.test2 <- varimp(rf2, conditional = T)
rf.test1
#variable importance is, in order: SNAP, SSI, CHIP, Medicaid, Population, Ed_Attain_HSandAbove, Pov_Rate, WIC, ED_Attain_BAandAbove
rf.test2
### Variable selection
#subsetting data for only dependent & Independent variables
etanf.x <- ETANFdata[, c(5:18)]
# fit the random forest
rf1 <- cforest(ETANF ~ ., data= etanf.x, control=cforest_unbiased(mtry=2,ntree=50))
rf2 <- cforest(ETANF ~ ., data= na.omit(etanf.x), control=cforest_unbiased(mtry=2,ntree=50))
# test for variable importance
set.seed(1234)
rf.test1 <- varimp(rf1)
rf.test2 <- varimp(rf2, conditional = T)
rf.test1
#variable importance is, in order: SNAP, SSI, CHIP, Medicaid, Population, Ed_Attain_HSandAbove, Pov_Rate, WIC, ED_Attain_BAandAbove
rf.test2
